context_size: 60
vocab_size: 5000

caption_decoder:
  stack_size: 6
  num_heads: 12
  hidden_size: 768
  key_size: 64
  value_size: 64
  feedforward_size: 3072
  dropout: 0.2

# Data loader
batch_size: 64
num_workers: 8 # Set according to your hardware

# Captioner training
total_epochs: 30
cur_epochs: 16
warmup_epochs: 2
lr: 1e-4
captioner_start_factor: 0.05
eta_min: 0
weight_decay: 0.1
label_smoothing: 0.01
eval_freq: 1

# Generation for metrics.
num_beams: 6
length_alpha: 0.8

unfreeze_lr_factor: 0.7
unfreeze_start_epoch: 3